# AMMI Final Project

Text Visual Questions and Answering is an integral part of communication. It takes the respondent the ability to comprehend what the speaker is asking and relate the text to visual objects in the scene including textual information, there to be an effective communication. This cuts across divers discipline, in which machine learning has a role to perform in ensuring that questions are understood and well answered. Researchers in Natural Language Processing and Computer Vision have been used various architectures such as Bottom-up and Top-Down Visual Attention Mechanism, Visual-BERT, M4C to mention a few. In this research, we looked into the application of multi-modal attention mechanism to improve the question and answering system.  We use multi-modal transformer with auto regressive answer generation to process the Text, Image and Optical Character Recognition(OCR).  Three approaches were proposed (Evaluating the pre-train model, fine-tuning the model with Google OCR and training from scratch). The first two approaches were implemented while the third is intended for future work. Hence,it was observed that the quality of answer generated from the pre-trained MC4 model with an improved OCR will enhance the performance for text visual question and answering system.
